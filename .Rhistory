l1 = str_replace(l1, 'polish, silesian', 'polish'),
l1 = str_replace(l1, 'swedish, finnish', 'swedish'),
l1 = str_replace(l1, 'greek, german', 'greek'),
l1 = str_replace(l1, 'russian, belarusian', 'russian'),
l1 = str_replace(l1, 'georgian, mingrelian', 'georgian'),
l1 = str_replace(l1, 'hi', 'chinese'),
l1 = str_replace(l1, 'cchinesenese', 'chinese'),
l1 = str_replace(l1, 'zhuang', 'chinese')) # chinese experiment
# Chunk 18: no l2 info
L2_info <- L2_info %>%
mutate(l2 = ifelse(l2 == " " | is.na(l2), "no_L2", l2),)
# Chunk 19: english as l2
L2_info <- mutate(L2_info,
EnglishL2YesNo = str_detect(l2, 'english'))
# Chunk 20: ls info cleaning
L2_info <- L2_info %>%
mutate(l2 = str_replace_all(l2, c('potuguese' = 'portuguese',
'spanich' = 'spanish',
'calatan' = 'catalan',
'ancient greek' = 'greek',
'rumanian' = 'romanian',
'estniska' = 'estonian',
'calabrese' = 'italian',
'dari' = 'farsi',
'\\(german\\)' = 'german',
'sami' = 'saami',
'inari saami' = 'saami',
"(a little bit )|(a little )" = "",
"\\s+" = " ",
"\\s+$" = "",
",(?![ ])" = ", ")))
# Chunk 21: add rhotic cols
L2_info <- L2_info %>%
mutate(r_l_distinction_L1 = NA,
trill_real_L1 = NA,
trill_occ_L1 = NA,
r_l_distinction_L2 = NA,
trill_real_L2 = NA,
trill_occ_L2 = NA)
# Chunk 22: add rhotic info l1
L2_info <- L2_info %>%
left_join(languages_data, by = c("l1" = "Languages")) %>%
mutate(r_l_distinction_L1 = coalesce(r_l_distinction, r_l_distinction_L1),
trill_real_L1 = coalesce(trill_real, trill_real_L1),
trill_occ_L1 = coalesce(trill_occ, trill_occ_L1)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ))
# Chunk 23: add rhotic info l2
# Save the original 'l2' column
original_l2 <- L2_info$l2
# Run the main code
L2_info <- L2_info %>%
separate_rows(l2, sep = ",\\s*") %>%
left_join(languages_data, by = c("l2" = "Languages")) %>%
group_by(ID) %>%
mutate(r_l_distinction_L2 = if(all(is.na(r_l_distinction))) NA else max(coalesce(r_l_distinction, r_l_distinction_L2), na.rm = TRUE),
trill_real_L2 = if(all(is.na(trill_real))) NA else max(coalesce(trill_real, trill_real_L2), na.rm = TRUE),
trill_occ_L2 = if(all(is.na(trill_occ))) NA else max(coalesce(trill_occ, trill_occ_L2), na.rm = TRUE)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ)) %>%
distinct(ID, .keep_all = TRUE) %>%
ungroup()
# Replace the original 'l2' column
L2_info$l2 <- original_l2
rm(original_l2)
# Chunk 24: l2 and web
web <- left_join(web, select(L2_info, -Language), by = c('ID' = 'ID'))
# Chunk 25: rename vars
web <- rename(web,
L1_raw = l1.x,
L2_raw = l2.x,
L1_cleaned = l1.y,
L2_cleaned = l2.y)
# Chunk 26: how many per participant
ppt_N <- web %>% count(ID)
# Chunk 27: check response N
all(ppt_N$n == 2)
# Chunk 28: check who
filter(ppt_N, n != 2)
# Chunk 29: remove less than 2
# Vector of participants to exclude:
excludes <- filter(ppt_N, n != 2) %>% pull(ID)
# Exclude:
web <- filter(web, !(ID %in% excludes))
rm(excludes)
# Chunk 30: counts per lang
web %>% count(Language) %>%
mutate(n = n / 2) %>%
print()
# Chunk 31: remove too few
web <- filter(web, Language != "MS")
web <- filter(web, Language != "TA")
# Chunk 32: sort l1
web <- filter(web,
!L1_cleaned %in% c('arabic',
'kurdish', 'pashto',
'wolof'))
# Close enough for our purposes from the perspective of kiki/bouba and the fact that language families don't cross â€” sorry if you are a speaker of one of these languages as we recognize the difference, but the most important thing is that these do not exert a bias from a "macro perspective" of language families:
web[web$L1_cleaned == 'dutch', ]$L1_cleaned <- 'german'
web[web$L1_cleaned == 'czech', ]$L1_cleaned <- 'polish'
web[web$L1_cleaned == 'latvian', ]$L1_cleaned <- 'polish'
# Chunk 33: clean l1
table(web$L1_cleaned, web$Language)
web[web$L1_cleaned == 'russian', ]$Language <- 'RU'
web[web$L1_cleaned == 'armenian', ]$Language <- 'AM'
web[web$L1_cleaned == 'chinese', ]$Language <- 'CN'
web[web$L1_cleaned == 'english', ]$Language <- 'EN'
web[web$L1_cleaned == 'estonian', ]$Language <- 'EE'
web[web$L1_cleaned == 'german', ]$Language <- 'DE'
web[web$L1_cleaned == 'finnish', ]$Language <- 'FI'
web[web$L1_cleaned == 'french', ]$Language <- 'FR'
web[web$L1_cleaned == 'italian', ]$Language <- 'IT'
web[web$L1_cleaned == 'korean', ]$Language <- 'KR'
web[web$L1_cleaned == 'polish', ]$Language <- 'PL'
web[web$L1_cleaned == 'zulu', ]$Language <- 'ZU'
web[web$L1_cleaned == 'spanish', ]$Language <- 'ES'
web[web$L1_cleaned == 'swedish', ]$Language <- 'SE'
web[web$L1_cleaned == 'portuguese', ]$Language <- 'PT'
web[web$L1_cleaned == 'thai', ]$Language <- 'TH'
# Chunk 34: load lang file
langs <- read_csv(paste0(data, 'language_info.csv'))
# Chunk 35: merge lang
web <- left_join(web, langs)
# Chunk 36: add resp
web <- rename(web,
Resp = inputvalue)
# Chunk 37: add condition
web <- mutate(web,
Condition = str_replace(audio, '\\.wav', ''))
# Chunk 38: congruency
web$match = web$Condition == web$Resp
# Chunk 39: trial
web$sound <- xfun::sans_ext(web$audio)
web$match <- web$sound == web$Resp
table(web$match)
# add trial
web$trial <- NA
for (subject in unique(web$ID)) {
idx <- which(web$ID == subject)
web$trial[idx] <- 1:length(idx)
}
table(web$trial)
out <- web[, c('ID', 'sex', 'Language', 'Name', 'Script', 'Family', 'Autotyp_Area', 'trial', 'sound', 'match')]
rm(idx, subject)
# Rename column names for consistency with the main analysis:
out <- rename(out, Condition = sound)
write_csv(out, paste0(data,'web_raw_trials.csv'))
# Chunk 40: ID tabs
ID_tabs <- with(web, table(Condition, Resp, ID))
# Chunk 41: matches
matches <- numeric(dim(ID_tabs)[3])
for (i in seq_along(matches)) {
matches[i] <- as.integer(sum(diag(ID_tabs[, , i])) == 2)
}
# Chunk 42: ids
ids <- unique(web$ID)
r_ppt <- tibble(ID = ids, Match = matches)
rm(ids, i, ID_tabs, matches)
# Chunk 43: get order for r_ppt
web <- web %>%
group_by(ID) %>%
mutate(Order = ifelse(trial == 1 & n() == 2,
ifelse(sound == "l", "l_first", "r_first"),
NA)) %>%
fill(Order, .direction = "updown") %>%
ungroup()
# Chunk 44: merge ppt
r_ppt$Language <- web[match(r_ppt$ID, web$ID), ]$Language
r_ppt$Sex <- web[match(r_ppt$ID, web$ID), ]$sex
r_ppt$Age <- web[match(r_ppt$ID, web$ID), ]$participantage
r_ppt$Name <- web[match(r_ppt$ID, web$ID), ]$Name
r_ppt$Script <- web[match(r_ppt$ID, web$ID), ]$Script
r_ppt$Family <- web[match(r_ppt$ID, web$ID), ]$Family
r_ppt$Autotyp_Area <- web[match(r_ppt$ID, web$ID), ]$Autotyp_Area
r_ppt$L2 <- web[match(r_ppt$ID, web$ID), ]$L2_raw
r_ppt$EnglishL2YesNo <- web[match(r_ppt$ID, web$ID), ]$EnglishL2YesNo
r_ppt$Order <- web[match(r_ppt$ID, web$ID), ]$Order
r_ppt$r_l_distinction_L1 <- web[match(r_ppt$ID, web$ID), ]$r_l_distinction_L1
r_ppt$trill_real_L1 <- web[match(r_ppt$ID, web$ID), ]$trill_real_L1
r_ppt$trill_occ_L1 <- web[match(r_ppt$ID, web$ID), ]$trill_occ_L1
r_ppt$r_l_distinction_L2 <- web[match(r_ppt$ID, web$ID), ]$r_l_distinction_L2
r_ppt$trill_real_L2 <- web[match(r_ppt$ID, web$ID), ]$trill_real_L2
r_ppt$trill_occ_L2 <- web[match(r_ppt$ID, web$ID), ]$trill_occ_L2
# Chunk 45: save cleaned data
write_csv(r_ppt, paste0(data, 'web_experiment_cleaned.csv'))
web <- read_csv(paste0(data, 'web_experiment_cleaned.csv'))
# Chunk 46: remove objects web
rm(L2_info, langs, out, ppt_N, r_ppt)
# Chunk 47: load demographics field
# Load:
demographics <- read_delim(paste0(data, 'fieldwork-personal-data.csv'), delim = ';')
# Chunk 48: fix colname
colnames(field)[ncol(field)] <- 'PA08'
# Chunk 49: reshape table
# Remove rows with names "bouba-ort", "bouba-aud", "kiki-ort", and "kiki-aud"
field <- field %>%
filter(!file %in% c("bouba-ort", "bouba-aud", "kiki-ort", "kiki-aud"))
field[1, -1] <- gsub("rock", "r", field[1, -1])
field <- field %>%
select(-file) %>%
pivot_longer(everything(), names_to = "ID", values_to = "value") %>%
arrange(ID) %>%  # Arrange by ID
group_by(ID) %>%
mutate(audio = rep(c("r", "l"), each = n() / 2),  # Repeat "r" and "l" for each ID
response = ifelse(value %in% c("0", "NA", " "), NA, value)) %>%
ungroup() %>%
select(-value)  # Remove the original "value" column
# Chunk 50: get lang info
field <- mutate(field,
Language = str_extract(ID, '[A-Z]+'),
Participant = str_extract(ID, '\\d+'))
# Chunk 51: add age gender
# Rename so that key columns match names:
demographics <- rename(demographics,
ID = subject,
Age = age,
Sex = gender,
L2 = "other-lang")
# Get only that what is needed:
demographics <- select(demographics,
ID, Age, Sex, L2)
# Join:
field <- left_join(field, demographics)
# Chunk 52: exclude polish
field <- filter(field, Language != 'US')
field <- filter(field, Language != 'PL')
# Chunk 53: how many field
length(unique(field$ID))
# Chunk 54: exclude field
field <- filter(field, Age > 18)
# Chunk 55
field %>%
group_by(ID) %>%
summarise(AllResponsesEmptyOrNA = all(is.na(response) | response == "")) %>%
filter(AllResponsesEmptyOrNA)
# Chunk 56
field <- field %>%
filter(ID != "BE40")
# Chunk 57: add info on contrast
field$Name <- NA
field[field$Language == 'BE', ]$Name <- 'english'
field[field$Language == 'DE', ]$Name <- 'german'
field[field$Language == 'SR', ]$Name <- 'portuguese'
field[field$Language == 'VA', ]$Name <- 'daakie'
field[field$Language == 'BR', ]$Name <- 'berber'
field[field$Language == 'PA', ]$Name <- 'palikur'
# Chunk 58: process l2
L2_info_field <- filter(field, !duplicated(ID)) %>% select(ID, Language, Sex, Name, L2)
# Chunk 59: add no l2
L2_info_field <- L2_info_field %>%
mutate(L2 = ifelse(L2 %in% c('0', 'NA', ' '), NA, L2)) %>%
mutate(L2 = ifelse(is.na(L2), 'no_L2', L2))
# also do it in the field df for the future
field <- field %>%
mutate(L2 = ifelse(L2 %in% c('0', 'NA', ' '), NA, L2))
# Chunk 60: add english
L2_info_field <- mutate(L2_info_field,
EnglishL2YesNo = ifelse(grepl('english', L2, ignore.case = TRUE), TRUE, FALSE))
# Chunk 61: l2 conversions
L2_info_field <- L2_info_field %>%
mutate(L2 = str_replace_all(L2, regex('British Sign Language', ignore_case = TRUE), 'BSL'),
L2 = str_replace_all(L2, regex('Mandarin', ignore_case = TRUE), 'chinese'),
L2 = str_replace_all(L2, regex('Moroccan Arabic', ignore_case = TRUE), 'arabic'),
L2 = str_replace_all(L2, regex('Standard Arabic', ignore_case = TRUE), 'arabic'))
L2_info_field <- L2_info_field %>%
mutate(L2 = ifelse(L2 %in% c("no_L2", "BSL"), L2, str_to_lower(L2))) %>%
rowwise() %>%
mutate(L2 = paste(unique(unlist(str_split(L2, ",\\s*"))), collapse = ", "))
L2_info_field$L2 <- sub("\\s*\\(restricted reading skills\\)", "", L2_info_field$L2)
# Chunk 62: add rhotic cols field
L2_info_field <- L2_info_field %>%
mutate(r_l_distinction_L1 = NA,
trill_real_L1 = NA,
trill_occ_L1 = NA,
r_l_distinction_L2 = NA,
trill_real_L2 = NA,
trill_occ_L2 = NA)
# Chunk 63: add rhotic info l1 field
L2_info_field <- L2_info_field %>%
left_join(languages_data, by = c("Name" = "Languages")) %>%
mutate(r_l_distinction_L1 = coalesce(r_l_distinction, r_l_distinction_L1),
trill_real_L1 = coalesce(trill_real, trill_real_L1),
trill_occ_L1 = coalesce(trill_occ, trill_occ_L1)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ))
# Chunk 64: add rhotic info l2 field
# Save the original 'l2' column
original_L2 <- L2_info_field$L2
# Run the main code
L2_info_field <- L2_info_field %>%
separate_rows(L2, sep = ",\\s*") %>%
left_join(languages_data, by = c("L2" = "Languages")) %>%
group_by(ID) %>%
mutate(r_l_distinction_L2 = if(all(is.na(r_l_distinction))) NA else max(coalesce(r_l_distinction, r_l_distinction_L2), na.rm = TRUE),
trill_real_L2 = if(all(is.na(trill_real))) NA else max(coalesce(trill_real, trill_real_L2), na.rm = TRUE),
trill_occ_L2 = if(all(is.na(trill_occ))) NA else max(coalesce(trill_occ, trill_occ_L2), na.rm = TRUE)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ)) %>%
distinct(ID, .keep_all = TRUE) %>%
ungroup()
# Replace the original 'L2' column
L2_info_field$L2 <- original_L2
rm(original_L2)
# Chunk 65: l2 and field
field <- left_join(field, select(L2_info_field, -Language), by = c('ID' = 'ID'))
# Chunk 66: rename vars field
field <- field %>%
rename(Name = Name.x,
L2_raw = L2.x,
L2_cleaned = L2.y) %>%
select(-Name.y)
# Chunk 67: how many per participant field
ppt_N <- field %>% count(ID)
# Chunk 68: check response N field
all(ppt_N$n == 2)
# Chunk 69: remove less than 2 field
rm(ppt_N)
# Chunk 70: counts per lang field
field %>% count(Name) %>%
mutate(n = n / 2) %>%
print()
# Chunk 71: load lang file field
langs <- read_csv(paste0(data, 'language_info_field.csv'))
# Chunk 72: merge lang field
field <- left_join(field, langs, by = "Language")
field <- field %>%
rename(Name = Name.y) %>%
select(-Name.x) %>%
rename(Sex = Sex.y) %>%
select(-Sex.x)
# Chunk 73: congruency field
field$match = field$audio == field$response
View(field)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60))
devtools::install_github('rpuggaardrode/praatpicture')
library(praatpicture)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60))
stimuli       <- paste0(parentfolder, '/stimuli/')
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60))
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(20,60))
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(20,80))
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60))
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,8000), spec_dynamicRange=70)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,8000), spec_dynamicRange=50)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,8000), spec_dynamicRange=40)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,8000), spec_dynamicRange=50)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,6000), spec_dynamicRange=50)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,6000), spec_dynamicRange=70)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,6000), spec_dynamicRange=50,
spec_windowShape='Hamming', spec_windowLength=0.03)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'), proportion=c(40,60),
spec_freqRange=c(0,6000), spec_dynamicRange=50,
spec_windowShape='Hamming', spec_windowLength=0.06)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
spec_freqRange=c(0,5000),
spec_dynamicRange=50,
#spec_windowShape='Hamming',
spec_windowLength=0.05)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
spec_freqRange=c(0,5000),
spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
img_l <- png::readPNG(paste0(stimuli, 'l.png'))
library(praatpicture)
library(ggplot2)
library(grid)
library(gridExtra)
library(png)
install.packages("png")
library(png)
library(magrittr)
img_l <- png::readPNG(paste0(stimuli, 'l.png'))
img_r <- png::readPNG(paste0(stimuli, 'r.png'))
img_l_spec <- praatpicture(paste0(stimuli, 'l.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
img_r_spec <- praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
plot_l <- ggplot() + annotation_custom(rasterGrob(img_l), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "a")
plot_r <- ggplot() + annotation_custom(rasterGrob(img_r), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "c")
plot_l_spec <- ggplot() + annotation_custom(rasterGrob(img_l_spectrogram), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "b")
plot_l_spec <- ggplot() + annotation_custom(rasterGrob(img_l_spec), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "b")
View(img_l_spec)
par(mfrow = c(2,2))
img_l
praatpicture(paste0(stimuli, 'l.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
img_r
library(EBImage)
install.packages("EBImage")
img_l <- readImage(paste0(stimuli, 'l.png'))
library(EBImage)
install.packages("magick")
library(magick)
img_l <- image_read(paste0(stimuli, 'l.png'))
img_r <- image_read(paste0(stimuli, 'r.png'))
par(mfrow = c(2,2))
img_l
praatpicture(paste0(stimuli, 'l.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
img_r
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
praatpicture(paste0(stimuli, 'r.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
praatpicture(paste0(stimuli, 'l.wav'),
frames=c('sound', 'spectrogram'),
proportion=c(40,60),
#spec_freqRange=c(0,5000),
#spec_dynamicRange=50,
#spec_windowShape='Hamming',
#spec_windowLength=0.05
)
img_l_spec <- image_read(paste0(stimuli, 'l_spec.png'))
img_r_spec <- image_read(paste0(stimuli, 'r_spec.png'))
plot_l <- ggplot() + annotation_custom(rasterGrob(img_l), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "a")
plot_r <- ggplot() + annotation_custom(rasterGrob(img_r), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "c")
plot_l_spectrogram <- ggplot() + annotation_custom(rasterGrob(img_l_spec), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "b")
plot_r_spectrogram <- ggplot() + annotation_custom(rasterGrob(img_r_spec), xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
labs(tag = "d")
final_plot <- (plot_l | plot_r) / (plot_l_spectrogram | plot_r_spectrogram)
# Add labels
img_l <- image_annotate(img_l, label = "a", location = "+20+30", size = 50, color = "red")
# Combine images horizontally
top_row <- image_append(c(img_l, img_r))
bottom_row <- image_append(c(img_l_spectrogram, img_r_spectrogram))
# Combine rows vertically to create a 2x2 grid
final_grid <- image_montage(image_scale(c(top_row, bottom_row), "400x400"), tile = "2x1")
bottom_row <- image_append(c(img_l_spec, img_r_spec))
# Combine rows vertically to create a 2x2 grid
final_grid <- image_montage(image_scale(c(top_row, bottom_row), "400x400"), tile = "2x1")
# View the final grid
image_view(final_grid)
final_grid
par(mfrow = c(2,2))
img_l
img_l_spec
img_r
img_r_spec
