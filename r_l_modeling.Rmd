---
title: "R/L across languages: Modeling"
author: "Aleksandra Ä†wiek"
date: "2023-10-26"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction:

This script uses the output of "r_l_preparation.Rmd" and returns all
values reported in the paper.

# Setup:

Load packages:

```{r, message = FALSE, warning = FALSE}
library(tidyverse) # data processing
library(brms) # bayesian models
#library(cmdstanr) # install it with: install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos"))) followed by install_cmdstan()
library(ggdist) # for plotting
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

## Set the script's path as working directory
#parentfolder = rstudioapi::getActiveDocumentContext()$path 
#setwd(dirname(parentfolder))
#parentfolder <- getwd()
parentfolder <- "."; # assume current folder is the document folder

models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
data          <- paste0(parentfolder, '/data/')
```

For reproducible reporting:

```{r, message = FALSE, warning = FALSE}
packageVersion('tidyverse')
packageVersion('ggplot2')
packageVersion('brms')
#packageVersion('cmdstanr')
packageVersion('ggdist')
```

Load ggplot2 theme and colors:

```{r, message = FALSE, warning = FALSE}
source('theme_timo.R')

colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                       "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Load data:

```{r, message = FALSE, warning = FALSE}
web     <- read_csv(paste0(data, 'web_experiment_cleaned.csv'))
web_raw <- read_csv(paste0(data, '/web_raw_trials.csv'))

field     <- read_csv(paste0(data, 'field_experiment_cleaned.csv'))
field_raw <- read_csv(paste0(data, '/field_raw_trials.csv'))
```

# Create summary table for article

```{r}
# Creating the desired table
summary_table_web <- web %>%
  group_by(Family, Name) %>%
  summarise(
    Num_IDs = n(), # Count of IDs
    r_l_distinction = unique(r_l_distinction_L1),
    trill_real_L1 = unique(trill_real_L1),
    trill_occ_L1 = unique(trill_occ_L1)
  )

# Output the table to a CSV file for use in Word
write.csv(summary_table_web, 'summary_table_web.csv', row.names = FALSE)

# Creating the desired table
summary_table_field <- field %>%
  group_by(Family, Name) %>%
  summarise(
    Num_IDs = n(), # Count of IDs
    r_l_distinction = unique(r_l_distinction_L1),
    trill_real_L1 = unique(trill_real_L1),
    trill_occ_L1 = unique(trill_occ_L1)
  )

# Output the table to a CSV file for use in Word
write.csv(summary_table_field, 'summary_table_field.csv', row.names = FALSE)
```


# Online experiment

## Descriptive statistics

First, how many participants?

```{r}
nrow(web)
```

Sex division

```{r}
table(web$Sex)
```

Ages

```{r}
summary(web$Age)
```

Order division

```{r}
# Counts
table(web$Order)
# Percentage
prop.table(table(web$Order)) * 100
```

First, how many languages?

```{r}
web %>% count(Name) %>% nrow()
```

Does this number correspond with the L1s?

```{r}
web %>% count(Language) %>% nrow()
```

How many families?

```{r}
web %>% count(Family) %>% nrow()
```

How many have the R/L distinction in the L1 among the languages?

```{r}
web %>% count(Language, r_l_distinction_L1) %>% count(r_l_distinction_L1)
```

How many really use the alveolar trill in L1 among the languages?

```{r}
web %>% count(Language, trill_real_L1) %>% count(trill_real_L1)
```

How many really have the alveolar trill in L1 as an allophone among the
languages?

```{r}
web %>% count(Language, trill_occ_L1) %>% count(trill_occ_L1)
```

What about the same questions for L2. But this will not neatly sum up to
25, due to various possible scenarios for L2 within a specific L1.

How many have the R/L distinction in the L2 among the languages?

```{r}
web %>% count(Language, r_l_distinction_L2) %>% count(r_l_distinction_L2)
```

How many really use the alveolar trill in L2 among the languages?

```{r}
web %>% count(Language, trill_real_L2) %>% count(trill_real_L2)
```

How many really have the alveolar trill in L2 as an allophone among the
languages?

```{r}
web %>% count(Language, trill_occ_L2) %>% count(trill_occ_L2)
```

What is the grand average congruent behavior?

```{r}
mean(web$Match)
```

87.3%

What about only among those who have L1 without the distinction?

```{r}
web %>%
  filter(r_l_distinction_L1 == "0") %>%
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

83.9%

What about only among those who have L1 without the distinction and no
L2 that distinguishes?

```{r}
web %>%
  filter(r_l_distinction_L1 == "0") %>%
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

85.1%

Compute average matching behavior per language and sort:

```{r}
web_avg <- web %>%
  group_by(Language) %>% 
  summarize(M = mean(Match)) %>% 
  arrange(desc(M)) %>% 
  mutate(percent = round(M, 2) * 100,
         percent = str_c(percent, '%'))

# Show:

web_avg %>% print(n = Inf)
```

Check some demographics, also to report in the paper. First, the number
of participants per language:

```{r}
web %>% 
  count(Name, sort = TRUE) %>% print(n = Inf)
```

Then, the number of L1 speakers who have R/L distinction vs. who don't:

```{r}
web %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Then, the number of L1 speakers who have alveolar trill vs. who don't:

```{r}
web %>% count(trill_real_L1) %>%
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those who don't have trill in L1, how many do in L2?

```{r}
web %>% filter(trill_real_L1 == 0) %>% 
  count(trill_real_L2 == 1) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```


```{r}
web %>% filter(trill_real_L1 == 0) %>% 
  filter(trill_real_L2 == 1) %>% 
  filter(trill_occ_L1 == 0) %>% 
  count(trill_occ_L2 == 1) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many people do not have any L2?

```{r}
sum(is.na(web$L2)) / nrow(web)

# bilinguals:
1 - sum(is.na(web$L2)) / nrow(web)
```

Check how many people knew English as their L2:

```{r}
web %>% count(EnglishL2YesNo) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those that don't use a R/L distinction in their L1, how many use R/L
distinction in their L2? (double-check if logic alright!)

```{r}
web %>%
  filter(r_l_distinction_L1 == 0) %>% 
  count(r_l_distinction_L2 == 1) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many "pure" speakers were there?, i.e., those people that 1) don't
know English, 2) don't use an L1 with a R/L distinction, and 3) don't
know an L2 that distinguishes R/L.

```{r}
web %>% 
  filter(r_l_distinction_L1 == 0) %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L2 == 0) %>% 
  nrow()
```

1 person!

Let's check if this is correct. This gives the list of all participants
for whom this applies.

```{r}
web %>% 
    filter(r_l_distinction_L1 == 0 & !EnglishL2YesNo & r_l_distinction_L2 == 0) %>% 
    print(n = 50)
```

Are these really "pure"? What languages do they speak?

```{r}
web %>% 
  filter(r_l_distinction_L1 == 0) %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L2 == 0) %>% 
  count(Language)
```

One Japanese speaker.

Nevertheless, let's explore whether these also show matches?

```{r}
web %>% 
  filter(r_l_distinction_L1 == 0) %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L2 == 0) %>% 
  count(Match) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Yes, similar to above 85%.


### L1 Only

The main model with Order and R/L distinction and alveolar trill as the
preferred variant in L1 as fixed effects, as well as by Language and
Family slopes and intercepts.

```{r, message = FALSE, warning = FALSE}
web_mdl_L1Only <- brm(Match ~ 1 + order_num + r_l_distinction_L1 + trill_real_L1 +
                        (1 + order_num|Language) + 
                        (1 + order_num|Family),
                      data = web,
                      family = bernoulli(link = 'logit'),
                      #backend = "cmdstanr",
                      seed = 998,
                      cores = 4,
                      iter = myiter,
                      warmup = mywarmup,
                      control = list(adapt_delta = 0.995,
                                     max_treedepth = 13),
                      file = paste0(models, "web_mdl_L1Only.rds"))




# test whether coding as factors matters:
web_mdl_L1Only_test <- brm(Match ~ 1 + order_num + r_l_distinction_L1 + trill_real_L1 + Sex + Age + 
                             (1 + order_num  | Language) + 
                             (1 + order_num + r_l_distinction_L1 + trill_real_L1 | Family),
                           (1 + order_num + r_l_distinction_L1 + trill_real_L1 | Autotyp_Area),
                           data = web,
                           family = bernoulli(link = 'logit'),
                           #backend = "cmdstanr",
                           seed = 998,
                           cores = 4,
                           iter = myiter,
                           warmup = mywarmup,
                           control = list(adapt_delta = 0.999,
                                          max_treedepth = 13))
summary(web_mdl_L1Only_test); mcmc_plot(web_mdl_L1Only_test, type="trace"); mcmc_plot(web_mdl_L1Only_test);
```

Show the model:

```{r}
web_mdl_L1Only
```

PPcheck fit:

```{r}
pp_check(web_mdl_L1Only, ndraws = 1000)
```

Compute grand averages with 95% lower and upper bound of credible
interval to report:

```{r}
plogis(fixef(web_mdl_L1Only)[1, ][1])
plogis(fixef(web_mdl_L1Only)[1, ][3]) # lwr bound
plogis(fixef(web_mdl_L1Only)[1, ][4]) # upr bound
```

Perform hypothesis tests:

```{r}
hypothesis(web_mdl_L1Only, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 < 0', 'order_num < 0'))
```

Meaning:

-   The r/l phoneme distinction within a language does not have an
    impact of matching r to rough picture/surface and l to smooth
    picture/surface. Speakers of languages that do and that do not
    differentiate between r and l are equally good/bad at matching.
-   Having a real alveolar trill as the main r-phoneme in a language has
    a negative (!) impact on matching, that is the languages that use
    the alveolar trill as their primary /r/ are likely to be worse at
    matching in our data.
-   There is an order effect with r_first trials resulting in better
    matching than l_first trials.

Check the descriptive averages for r/l and order:

```{r}
web %>% 
  group_by(r_l_distinction_L1) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

```{r}
web %>% 
  group_by(trill_real_L1) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

```{r}
web %>% 
  group_by(Order) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Extract the posteriors:

```{r}
posts <- posterior_samples(web_mdl_L1Only)
posts <- select(posts,
                b_Intercept:b_trill_real_L1)
```

Make the posteriors into long format for plotting (Figure 3):

```{r}
posts <- pivot_longer(posts,
                      cols = b_Intercept:b_trill_real_L1,
                      names_to = 'coefficient',
                      values_to = 'posterior')
```

Change names for plotting and order:

```{r}
posts <- posts %>%
  mutate(coefficient = ifelse(coefficient == 'b_Intercept', 'Intercept', coefficient),
         coefficient = ifelse(coefficient == 'b_order_num', 'Order', coefficient),
         coefficient = ifelse(coefficient == 'b_r_l_distinction_L1', 'R/L distinction', coefficient),
         coefficient = ifelse(coefficient == 'b_trill_real_L1', '[r] is primary rhotic', coefficient),
         coefficient = factor(coefficient,
                              levels = rev(c('Intercept', 'Order', 'R/L distinction', '[r] is primary rhotic'))))
```

Make a plot of this:

```{r, fig.width = 8, fig.height = 7}
# Aesthetics and geom:

p <- posts %>% ggplot(aes(y = coefficient, x = posterior)) +
  geom_vline(aes(xintercept = 0), linetype = 2) +
  stat_halfeye(alpha = 0.5, fill = 'steelblue')

# Axis labels and coordinates:

p <- p +
  coord_cartesian(xlim = c(-4, +6)) +
  scale_x_continuous(breaks = seq(-4, 6, 1)) +
  xlab('Coefficient') +
  ylab(NULL)

# Tweak cosmetics:

p <- p +
  theme_timo + 
  theme(axis.title.x = element_text(margin = margin(t = 12, b = 0,
                                                    r = 0, l = 0),
                                    face = 'bold', size = 14),
        axis.text.x = element_text(face = 'bold', size = 12),
        axis.text.y = element_text(face = 'bold', size = 12))

# Show and save:

p
ggsave(plot = p, filename = paste0(plots, 'web_mdl_L1Only_coefficients.pdf'),
       width = 8, height = 6)
```

For Figure 4, we want to combine the predictions for each language with
the averages of each language. First, we need to get the predictions
from the model:

```{r}
# Setup data frame with predictors to get predictions for:
newdata <- data.frame(Language = unique(web$Language))
newdata$order_num <- 0
newdata$trill_real_L1 <- web[match(newdata$Language, web$Language), ]$trill_real_L1
newdata$r_l_distinction_L1 <- web[match(newdata$Language, web$Language), ]$r_l_distinction_L1
newdata$Family <- web[match(newdata$Language, web$Language), ]$Family

# Get predictions and append to dataframe:

fit <- fitted(web_mdl_L1Only, newdata = newdata,
              re_formula = NULL, robust = TRUE)
colnames(fit) = c('fit', 'se', 'lwr', 'upr')
newdata <- cbind(newdata, fit)

# Order predictions by descriptive average:

newdata <- arrange(newdata, fit)
newdata <- mutate(newdata,
                  Language = factor(Language, levels = newdata$Language))
```

How many languages are over 0.5? (will be reported in paper)

```{r}
sum(newdata$lwr > 0.5)
```

Finally, add the averages to the plot:

```{r}
newdata$avg <- web_avg[match(newdata$Language, web_avg$Language), ]$M
```

Match language names into there and order:

```{r}
newdata$Language <- web[match(newdata$Language, web$Language), ]$Name
newdata[newdata$Language == 'Chinese', ]$Language <- 'Mandarin Chinese'

newdata <- mutate(newdata,
                  Language = factor(Language, levels = newdata$Language))
```

Convert r_l_distinction_L1 and trill_real_L1 to categorical with 'yes'
and 'no'

```{r}
newdata$r_l_distinction_L1 <- factor(ifelse(newdata$r_l_distinction_L1 == 1, "yes", "no"), 
                                     levels = c("no", "yes"))
newdata$trill_real_L1 <- factor(ifelse(newdata$trill_real_L1 == 1, "yes", "no"), 
                                levels = c("no", "yes"))

```

Setup the plot:

```{r, fig.width = 8, fig.height = 6}
# Aesthetics and geom:

p <- newdata %>% 
  ggplot(aes(x = Language, col = r_l_distinction_L1, y = fit,
             ymin = lwr, ymax = upr, shape = trill_real_L1)) +
  #scale_shape_manual(values = c("no" = 1, "yes" = 3)) +
  geom_errorbar(aes(col = r_l_distinction_L1),
                size = 1.6, width = 0.6) +
  geom_point(size = 9) +
  geom_hline(yintercept = 0.5, linetype = 2, size = 1.5, col = 'grey') + 
  geom_point(aes(y = avg), col = 'black', shape = 23, size = 8.5,
              stroke = 1.5, alpha = 0.8)
  
# Axis labels:

p <- p +
  labs(x = '', y = 'Proportion\nof congruent responses') +
  ggtitle('Posterior medians and descriptive averages of congruent responses\nby language and R/L contrast (color) and [r] as primary rhotic in L1 (shape)') 

# Tweak cosmetics:

p <- p +
  scale_color_manual(values = c(colorBlindBlack8[2], colorBlindBlack8[3])) +
  theme_timo + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = 'bold',
                                   size = 30),
        axis.text.y = element_text(face = 'bold', size = 24),
        axis.title = element_text(face = 'bold', size = 40),
        axis.title.y = element_text(face = 'bold', size = 40,
                                    margin = margin(t = 0, r = 35,
                                                    b = 0, l = 0)),
        plot.title = element_text(face = 'bold', size = 40,
                                  margin = margin(t = 0, r = 0,
                                                  b = 30, l = 0)),
        legend.text = element_text(size = 30),
        legend.title = element_blank(),
        legend.position = c(0.95, 0.15),
        legend.justification = c('right', 'bottom'))

# Show and save:

p
ggsave(plot = p, filename = paste0(plots, 'web_mdl_L1Only_by_language.pdf'),
       width = 28, height = 12)
```

### L1 and L2 Only

The model with Order and R/L distinction and alveolar trill as the
preferred variant in L1 and in L2 as fixed effects, as well as by
Language and Family slopes and intercepts.

```{r, message = FALSE, warning = FALSE}
web_mdl_L1L2 <- brm(Match ~ 1 + order_num + r_l_distinction_L1 + trill_real_L1 + 
                      r_l_distinction_L2 + trill_real_L2 + 
                 (1 + order_num|Language) + 
                 (1 + order_num|Family),
                data = web,
                family = bernoulli(link = 'logit'),
                #backend = "cmdstanr",
                seed = 998,
                cores = 4,
                iter = myiter,
                warmup = mywarmup,
                control = list(adapt_delta = 0.995,
                               max_treedepth = 13),
                file = paste0(models, "web_mdl_L1L2.rds"))
```

Show the model:

```{r}
web_mdl_L1L2
```

@Dan, when I included trill_occ_L2, the Rhat was through the roof plus
treedepth errors. So I removed it, because there weren't that many
occurences and I wanted to see. Now without trill_occ_L2, the Rhats are
alright, but the convergence is still poor, treedepth errors. This is
the warning I got: 1: Rows containing NAs were excluded from the model.
2: There were 4959 transitions after warmup that exceeded the maximum
treedepth. Increase max_treedepth above 13. See
<https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded> 3:
Examine the pairs() plot to diagnose sampling problems

And yes, there are a lot of NAs in the L2 data, because not everyone has
an L2. Maybe that is the issue, but I will leave it at that for now.
Perhaps the L1 model is enough.


# Field experiment

## Descriptive statistics

First, how many participants?

```{r}
nrow(field)
```

Sex division

```{r}
table(field$Sex)
```

Ages

```{r}
summary(field$Age)
```

First, how many languages?

```{r}
field %>% count(Language) %>% nrow()
```

Does this number correspond with the L1s?

```{r}
field %>% count(Name) %>% nrow()
```

How many families?

```{r}
field %>% count(Family) %>% nrow()
```

How many have the R/L distinction in the L1 among the languages?

```{r}
field %>% count(Name, r_l_distinction_L1) %>% count(r_l_distinction_L1)
```

How many really use the alveolar trill in L1 among the languages?

```{r}
field %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
```

How many really have the alveolar trill in L1 as an allophone among the
languages?

```{r}
field %>% count(Name, trill_occ_L1) %>% count(trill_occ_L1)
```

What about the same questions for L2. But this will not neatly sum up to
25, due to various possible scenarios for L2 within a specific L1.

How many have the R/L distinction in the L2 among the languages?

```{r}
field %>% count(Name, r_l_distinction_L2) %>% count(r_l_distinction_L2)
```

How many really use the alveolar trill in L2 among the languages?

```{r}
field %>% count(Name, trill_real_L2) %>% count(trill_real_L2)
```

How many really have the alveolar trill in L2 as an allophone among the
languages?

```{r}
field %>% count(Name, trill_occ_L2) %>% count(trill_occ_L2)
```

What is the grand average congruent behavior?

```{r}
mean(field$Match)
```

97%!!!

What about only among those who have L1 without the distinction?

```{r}
field %>%
  filter(r_l_distinction_L1 == "0") %>%
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

100%! WOW.

What about only among those who have L1 without the distinction and no
L2 that distinguishes?

```{r}
field %>%
  filter(r_l_distinction_L1 == "0") %>%
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L2 == '0') %>% 
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

There are no such people.

Compute average matching behavior per language and sort:

```{r}
field_avg <- field %>%
  group_by(Language) %>% 
  summarize(M = mean(Match)) %>% 
  arrange(desc(M)) %>% 
  mutate(percent = round(M, 2) * 100,
         percent = str_c(percent, '%'))

# Show:

field_avg %>% print(n = Inf)
```

Check some demographics, also to report in the paper. First, the number
of participants per language:

```{r}
field %>% 
  count(Name, sort = TRUE) %>% print(n = Inf)
```

Then, the number of L1 speakers who have R/L distinction vs. who don't:

```{r}
field %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many people do not have any L2?

```{r}
# raw count of no L2; raw count of all ppl
sum(is.na(field$L2)); nrow(field)

# percentage no L2
sum(is.na(field$L2)) / nrow(field)

# percentage with L2
1 - sum(is.na(field$L2)) / nrow(field)
```

Check how many people knew English as their L2:

```{r}
field %>% count(EnglishL2YesNo) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those that don't use a R/L distinction in their L1, how many use R/L
distinction in their L2? (double-check if logic alright!)

```{r}
field %>%
  filter(r_l_distinction_L1 == '0') %>% 
  count(r_l_distinction_L2 == '1') %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```


How many speak trill in L1?

```{r}
field %>% 
  count(trill_real_L1 == 1) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those who don't have trill in L1, how many do in L2?

```{r}
field %>% filter(trill_real_L1 == 0) %>% 
  count(trill_real_L2 == 1) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```


```{r}
field %>% filter(trill_real_L1 == 0) %>% 
  filter(trill_real_L2 == 0) %>% 
  filter(trill_occ_L1 == 0) %>% 
  count(trill_occ_L2 == 0) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```


How many "pure" speakers were there?, i.e., those people that 1) don't
know English, 2) don't use an L1 with a R/L distinction, and 3) don't
know an L2 that distinguishes R/L.

```{r}
field %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L2 == '0') %>% 
  nrow()
```

None.

## Main model:

Check the distribution of scripts across families to make decisions
about random effects structure:

```{r}
table(field$Family, field$r_l_distinction_L1)
```

@Dan & @Bodo, can you please check if we need some manipulation, like
contrast-coding but weighted? Bodo, I know for bouba/kiki you did some
kind of weighted modification and I'm sure that the proportions of our
predictors are not balanced, see below:

```{r}
field %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n))
# highly imbalanced

field %>% count(trill_real_L1) %>%
  mutate(prop = n / sum(n))

field %>% count(trill_occ_L1) %>%
  mutate(prop = n / sum(n))
# highly imbalanced

## And for L2, just in case
field %>% count(r_l_distinction_L2) %>%
  mutate(prop = n / sum(n))

field %>% count(trill_real_L2) %>%
  mutate(prop = n / sum(n))

field %>% count(trill_occ_L2) %>%
  mutate(prop = n / sum(n))
```

### L1 Only

The main model with R/L distinction, alveolar trill as the preferred
variant, and allophonic alveolar trill in L1 as fixed effects, as well
as by Language and Family slopes and intercepts.

```{r, message = FALSE, warning = FALSE}
field_mdl_L1Only <- brm(Match ~ 1 + r_l_distinction_L1 + trill_real_L1 + trill_occ_L1 +
                 (1 |Language),
                data = field,
                family = bernoulli(link = 'logit'),
                #backend = "cmdstanr",
                seed = 998,
                cores = 4,
                iter = 10000,
                warmup = 5000,
                control = list(adapt_delta = 0.995,
                               max_treedepth = 15),
                file = paste0(models, "field_mdl_L1Only.rds"))
```

First try with the same parameters as web mdls:

> 1: There were 11534 transitions after warmup that exceeded the maximum
> treedepth. Increase max_treedepth above 13. See
> <https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded>\
> 2: Examine the pairs() plot to diagnose sampling problems\
> 3: The largest R-hat is 2.62, indicating chains have not mixed.
> Running the chains for more iterations may help. See
> <https://mc-stan.org/misc/warnings.html#r-hat>\
> 4: Bulk Effective Samples Size (ESS) is too low, indicating posterior
> means and medians may be unreliable. Running the chains for more
> iterations may help. See
> <https://mc-stan.org/misc/warnings.html#bulk-ess>\
> 5: Tail Effective Samples Size (ESS) is too low, indicating posterior
> variances and tail quantiles may be unreliable. Running the chains for
> more iterations may help. See
> <https://mc-stan.org/misc/warnings.html#tail-ess>

```         
 Family: bernoulli 
  Links: mu = logit 
Formula: Match ~ 1 + r_l_distinction_L1 + trill_real_L1 + trill_occ_L1 + (1 | Language) + (1 | Family) 
   Data: field (Number of observations: 126) 
  Draws: 4 chains, each with iter = 8000; warmup = 4000; thin = 1;
         total post-warmup draws = 16000

Group-Level Effects: 
~Family (Number of levels: 4) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     5.54      5.05     0.45    18.49 1.13       29      176

~Language (Number of levels: 6) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     1.58      1.34     0.05     5.23 1.10       32       20

Population-Level Effects: 
                    Estimate Est.Error   l-95% CI  u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept             103.33    152.58       2.87    630.55 1.15       18       15
r_l_distinction_L1  56887.37 186857.16 -184696.81 456418.45 2.62        5       16
trill_real_L1          24.79     21.28       0.32     74.78 1.15       18       42
trill_occ_L1       -56994.75 186834.76 -456446.19 184680.49 2.61        5       16

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
```

Modifications:

-   max_treedepth increased to 15

-   iter increased to 10k

-   warmup increased to 5k

-   removed by-family slope and intercept

Then, it got even worse?

> 1: There were 18766 transitions after warmup that exceeded the maximum
> treedepth. Increase max_treedepth above 15. See
> <https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded>\
> 2: Examine the pairs() plot to diagnose sampling problems\
> 3: The largest R-hat is 3.63, indicating chains have not mixed.
> Running the chains for more iterations may help. See
> <https://mc-stan.org/misc/warnings.html#r-hat>\
> 4: Bulk Effective Samples Size (ESS) is too low, indicating posterior
> means and medians may be unreliable. Running the chains for more
> iterations may help. See
> <https://mc-stan.org/misc/warnings.html#bulk-ess>\
> 5: Tail Effective Samples Size (ESS) is too low, indicating posterior
> variances and tail quantiles may be unreliable. Running the chains for
> more iterations may help. See
> <https://mc-stan.org/misc/warnings.html#tail-ess>

```         
 Family: bernoulli 
  Links: mu = logit 
Formula: Match ~ 1 + r_l_distinction_L1 + trill_real_L1 + trill_occ_L1 + (1 | Language) 
   Data: field (Number of observations: 126) 
  Draws: 4 chains, each with iter = 10000; warmup = 5000; thin = 1;
         total post-warmup draws = 20000

Group-Level Effects: 
~Language (Number of levels: 6) 
              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)     2.63      2.75     0.29    10.87 1.40        9       47

Population-Level Effects: 
                     Estimate  Est.Error    l-95% CI   u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept               38.69      28.66        2.59     106.97 1.07       53      152
r_l_distinction_L1  160913.21 1261024.44 -1752983.46 2301895.06 3.64        4       11
trill_real_L1            6.52       5.77       -0.74      23.36 1.12       26       12
trill_occ_L1       -160950.11 1261029.00 -2301955.01 1752918.28 3.64        4       11

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).
```




Show the model:

```{r}
field_mdl_L1Only
```

