---
title: "R/L across languages: Modeling"
author: "Aleksandra Ćwiek"
date: "2023-10-26"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction:

This script uses the output of "r_l_preparation.Rmd" and returns all values reported in the paper.

# Setup:

Load packages:

```{r, message = FALSE, warning = FALSE}
library(tidyverse) # data processing
library(brms) # bayesian models
library(cmdstanr)
library(ggdist) # for plotting
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path 
setwd(dirname(parentfolder))
parentfolder <- getwd()

models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
data          <- paste0(parentfolder, '/data/')
```

For reproducible reporting:

```{r, message = FALSE, warning = FALSE}
packageVersion('tidyverse')
packageVersion('ggplot2')
packageVersion('brms')
packageVersion('cmdstanr')
packageVersion('ggdist')
```

Load ggplot2 theme:

```{r, message = FALSE, warning = FALSE}
source('theme_timo.R')
```

Load data:

```{r, message = FALSE, warning = FALSE}
web <- read_csv(paste0(data, 'web_experiment_cleaned.csv'))
web_raw <- read_csv(paste0(data, '/web_raw_trials.csv'))

field <- read_csv(paste0(data, 'field_experiment_cleaned.csv'))
field_raw <- read_csv(paste0(data, '/field_raw_trials.csv'))
```

# Online experiment

## Descriptive statistics

First, how many participants?

```{r}
nrow(web)
```

Sex division

```{r}
table(web$Sex)
```

Ages

```{r}
summary(web$Age)
```

Order division

```{r}
# Counts
table(web$Order)
# Percentage
prop.table(table(web$Order)) * 100
```

First, how many languages?

```{r}
web %>% count(Language) %>% nrow()
```

Does this number correspond with the L1s?

```{r}
web %>% count(Name) %>% nrow()
```

How many families?

```{r}
web %>% count(Family) %>% nrow()
```

How many have the R/L distinction in the L1 among the languages?

```{r}
web %>% count(Name, r_l_distinction_L1) %>% count(r_l_distinction_L1)
```

How many really use the alveolar trill in L1 among the languages?

```{r}
web %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
```

How many really have the alveolar trill in L1 as an allophone among the languages?

```{r}
web %>% count(Name, trill_occ_L1) %>% count(trill_occ_L1)
```

What about the same questions for L2. But this will not neatly sum up to 25, due to various possible scenarios for L2 within a specific L1.

How many have the R/L distinction in the L2 among the languages?

```{r}
web %>% count(Name, r_l_distinction_L2) %>% count(r_l_distinction_L2)
```

How many really use the alveolar trill in L2 among the languages?

```{r}
web %>% count(Name, trill_real_L2) %>% count(trill_real_L2)
```

How many really have the alveolar trill in L2 as an allophone among the languages?

```{r}
web %>% count(Name, trill_occ_L2) %>% count(trill_occ_L2)
```

What is the grand average congruent behavior?

```{r}
mean(web$Match)
```

87%

What about only among those who have L1 without the distinction?

```{r}
web %>%
  filter(r_l_distinction_L1 == "0") %>%
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

83.9%

What about only among those who have L1 without the distinction and no L2 that distinguishes?

```{r}
web %>%
  filter(r_l_distinction_L1 == "0") %>%
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

85.1%

Compute average matching behavior per language and sort:

```{r}
web_avg <- web %>%
  group_by(Name) %>% 
  summarize(M = mean(Match)) %>% 
  arrange(desc(M)) %>% 
  mutate(percent = round(M, 2) * 100,
         percent = str_c(percent, '%'))

# Show:

web_avg %>% print(n = Inf)
```

Check some demographics, also to report in the paper. First, the number of participants per language:

```{r}
web %>% 
  count(Name, sort = TRUE) %>% print(n = Inf)
```


Then, the number of L1 speakers who have R/L distinction vs. who don't:

```{r}
web %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many people do not have any L2?

```{r}
sum(is.na(web$L2)) / nrow(web)

# bilinguals:
1 - sum(is.na(web$L2)) / nrow(web)
```

Check how many people knew English as their L2:

```{r}
web %>% count(EnglishL2YesNo) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those that don't use a R/L distinction in their L1, how many use R/L distinction in their L2? (double-check if logic alright!)

```{r}
web %>%
  filter(r_l_distinction_L1 == '0') %>% 
  count(r_l_distinction_L2 == '1') %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many "pure" speakers were there?, i.e., those people that 1) don't know English, 2) don't use an L1 with a R/L distinction, and 3) don't know an L2 that distinguishes R/L.

```{r}
web %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  nrow()
```

47 people.

Let's check if this is correct. This gives the list of all participants for whom this applies.

```{r}
web %>% 
    filter(r_l_distinction_L1 == '0' & !EnglishL2YesNo & r_l_distinction_L1 == '0') %>% 
    print(n = 50)
```

Are these really "pure"? What languages do they speak?

```{r}
web %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  count(Language)
```

Mostly Chinese and Japanese native speakers.

Nevertheless, let's explore whether these also show matches?

```{r}
web %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  count(Match) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Yes, similar to above 85%.

## Main model:


Set parameters that will be used for all MCMC sampling:

```{r}
mywarmup <- 4000
myiter <- 6000
```

Check the distribution of scripts across families to make decisions about random effects structure:

```{r}
table(web$Family, web$r_l_distinction_L1)
```

Let's factor code the Order and L1_distinction effects:

```{r}
web <- mutate(web,
               Order = factor(Order, levels = c('r_first', 'l_first')))
```

Check that the order effect is approximately balanced:

```{r}
web %>% count(Order) %>%
  mutate(prop = n / sum(n))
```

@Dan & @Bodo, can you please check if we need some manipulation, like contrast-coding but weighted? Bodo, I know for bouba/kiki you did some kind of weighted modification and I'm sure that the proportions of our predictors are not balanced, see below:

```{r}
web %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n))
# highly imbalanced

web %>% count(trill_real_L1) %>%
  mutate(prop = n / sum(n))

web %>% count(trill_occ_L1) %>%
  mutate(prop = n / sum(n))
# ALL L1 have some kind of occuring trill, so this is not even worth including in the model as predictor

## And for L2, just in case
web %>% count(r_l_distinction_L2) %>%
  mutate(prop = n / sum(n))

web %>% count(trill_real_L2) %>%
  mutate(prop = n / sum(n))

web %>% count(trill_occ_L2) %>%
  mutate(prop = n / sum(n))
```

For now, I will just use them as they are coded.

```{r}
web <- mutate(web,
               order_num = ifelse(Order == 'r_first', -0.5, +0.5))
```

The main model with Order and R/L distinction and alveolar trill as the preferred variant in L1 as fixed effects, as well as by Language and Family slopes and intercepts.

```{r, message = FALSE, warning = FALSE}
web_mdl <- brm(Match ~ 1 + order_num + r_l_distinction_L1 + trill_real_L1 +
                 (1 + order_num|Language) + 
                 (1 + order_num|Family),
                data = web,
                family = bernoulli(link = 'logit'),
                backend = "cmdstanr",
                seed = 42,
                cores = 4,
                iter = 2000,
                warmup = 1000,
                control = list(adapt_delta = 0.995,
                               max_treedepth = 13),
                file = paste0(models, "web_mdl2.rds"))
```

Show the model:

```{r}
web_mdl
```


Compute grand averages with 95% lower and upper bound of credible interval to report:

```{r}
plogis(fixef(web_mdl)[1, ][1])
plogis(fixef(web_mdl)[1, ][3]) # lwr bound
plogis(fixef(web_mdl)[1, ][4]) # upr bound
```

Perform hypothesis tests:

```{r}
hypothesis(web_mdl, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 < 0', 'order_num < 0'))
```

Meaning:

  - The r/l phoneme distinction within a language does not have an impact of matching r to rough picture/surface and l to smooth picture/surface. Speakers of languages that do and that do not differentiate between r and l are equally good/bad at matching.
  - Having a real alveolar trill as the main r-phoneme in a language has a negative (!) impact on matching, that is the languages that use the alveolar trill as their primary /r/ are likely to be worse at matching in our data.
  - There is an order effect with r_first trials resulting in better matching than l_first trials.

Check the descriptive averages for script and order:

```{r}
web %>% 
  group_by(r_l_distinction_L1) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

```{r}
web %>% 
  group_by(trill_real_L1) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

```{r}
web %>% 
  group_by(Order) %>% 
  summarize(prop = mean(Match)) %>% 
  mutate(percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Extract the posteriors:

```{r}
posts <- posterior_samples(web_mdl)
posts <- select(posts,
                b_Intercept:b_trill_real_L1)
```


Make the posteriors into long format for plotting (Figure 3):

```{r}
posts <- pivot_longer(posts,
                      cols = b_Intercept:b_trill_real_L1,
                      names_to = 'coefficient',
                      values_to = 'posterior')
```

Change names for plotting and order:

```{r}
posts <- posts %>%
  mutate(coefficient = ifelse(coefficient == 'b_Intercept', 'Intercept', coefficient),
         coefficient = ifelse(coefficient == 'b_order_num', 'Order', coefficient),
         coefficient = ifelse(coefficient == 'b_r_l_distinction_L1', 'R/L distinction', coefficient),
         coefficient = ifelse(coefficient == 'b_trill_real_L1', 'Primary [r]', coefficient),
         coefficient = factor(coefficient,
                              levels = rev(c('Intercept', 'Order', 'R/L distinction', 'Primary [r]'))))
```

Make a plot of this:

```{r, fig.width = 8, fig.height = 7}
# Aesthetics and geom:

p <- posts %>% ggplot(aes(y = coefficient, x = posterior)) +
  geom_vline(aes(xintercept = 0), linetype = 2) +
  stat_halfeye(alpha = 0.5, fill = 'steelblue')

# Axis labels and coordinates:

p <- p +
  coord_cartesian(xlim = c(-4, +6)) +
  scale_x_continuous(breaks = seq(-4, 6, 1)) +
  xlab('Coefficient') +
  ylab(NULL)

# Tweak cosmetics:

p <- p +
  theme_timo + 
  theme(axis.title.x = element_text(margin = margin(t = 12, b = 0,
                                                    r = 0, l = 0),
                                    face = 'bold', size = 14),
        axis.text.x = element_text(face = 'bold', size = 12),
        axis.text.y = element_text(face = 'bold', size = 12))

# Show and save:

p
ggsave(plot = p, filename = paste0(plots, 'main_model_coefficients.pdf'),
       width = 8, height = 6)
```


For Figure 4, we want to combine the predictions for each language with the averages of each language. First, we need to get the predictions from the model:

```{r}
# Setup data frame with predictors to get predictions for:
newdata <- data.frame(Language = unique(web$Language))
newdata$order_num <- 0
newdata$trill_real_L1 <- 0
newdata$r_l_distinction_L1 <- web[match(newdata$Language, web$Language), ]$r_l_distinction_L1
newdata$Family <- web[match(newdata$Language, web$Language), ]$Family

# Get predictions and append to dataframe:

fit <- fitted(web_mdl, newdata = newdata,
              re_formula = NULL, robust = TRUE)
colnames(fit) = c('fit', 'se', 'lwr', 'upr')
newdata <- cbind(newdata, fit)

# Order predictions by descriptive average:

newdata <- arrange(newdata, fit)
newdata <- mutate(newdata,
                  Language = factor(Language, levels = newdata$Language))
```

How many languages are over 0.5? (will be reported in paper)

```{r}
sum(newdata$lwr > 0.5)
```

Finally, add the averages to the plot:

```{r}
newdata$avg <- web_avg[match(newdata$Language, web_avg$Language), ]$M
```

Match language names into there and order:

```{r}
newdata$Language <- web[match(newdata$Language, web$Language), ]$Name
newdata[newdata$Language == 'Chinese', ]$Language <- 'Mandarin Chinese'

newdata <- mutate(newdata,
                  Language = factor(Language, levels = newdata$Language))
```

Setup the plot:

```{r, fig.width = 8, fig.height = 6}
# Aesthetics and geom:

p <- newdata %>% 
  ggplot(aes(x = Language, col = r_l_distinction_L1, y = fit,
      ymin = lwr, ymax = upr)) +
  geom_errorbar(aes(col = r_l_distinction_L1),
                size = 1.6, width = 0.6) +
  geom_point(size = 9, shape = 15) +
  geom_hline(yintercept = 0.5, linetype = 2, size = 1.5, col = 'grey') + 
  geom_point(aes(y = avg), col = 'black', shape = 23, size = 8.5,
             fill = 'white', stroke = 1.5)
  
# Axis labels:

p <- p +
  labs(x = '', y = 'Proportion\nof congruent responses') +
  ggtitle('Posterior medians and descriptive averages of\ncongruent responses by language and R/L contrast') 

# Tweak cosmetics:

p <- p +
  #scale_color_manual(values = c('#9C1437', '#355691')) + # ZAS-COLORS
  theme_timo + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, face = 'bold',
                                   size = 30),
        axis.text.y = element_text(face = 'bold', size = 24),
        axis.title = element_text(face = 'bold', size = 40),
        axis.title.y = element_text(face = 'bold', size = 40,
                                    margin = margin(t = 0, r = 35,
                                                    b = 0, l = 0)),
        plot.title = element_text(face = 'bold', size = 40,
                                  margin = margin(t = 0, r = 0,
                                                  b = 30, l = 0)),
        legend.text = element_text(size = 30),
        legend.title = element_blank(),
        legend.position = c(0.95, 0.15),
        legend.justification = c('right', 'bottom'))

# Show and save:

p
ggsave(plot = p, filename = paste0(plots, 'by_language_results.pdf'),
       width = 28, height = 12)
```


# Field experiment

## Descriptive statistics

First, how many participants?

```{r}
nrow(field)
```

Sex division

```{r}
table(field$Sex)
```

Ages

```{r}
summary(field$Age)
```

First, how many languages?

```{r}
field %>% count(Language) %>% nrow()
```

Does this number correspond with the L1s?

```{r}
field %>% count(Name) %>% nrow()
```

How many families?

```{r}
field %>% count(Family) %>% nrow()
```

How many have the R/L distinction in the L1 among the languages?

```{r}
field %>% count(Name, r_l_distinction_L1) %>% count(r_l_distinction_L1)
```

How many really use the alveolar trill in L1 among the languages?

```{r}
field %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
```

How many really have the alveolar trill in L1 as an allophone among the languages?

```{r}
field %>% count(Name, trill_occ_L1) %>% count(trill_occ_L1)
```

What about the same questions for L2. But this will not neatly sum up to 25, due to various possible scenarios for L2 within a specific L1.

How many have the R/L distinction in the L2 among the languages?

```{r}
field %>% count(Name, r_l_distinction_L2) %>% count(r_l_distinction_L2)
```

How many really use the alveolar trill in L2 among the languages?

```{r}
field %>% count(Name, trill_real_L2) %>% count(trill_real_L2)
```

How many really have the alveolar trill in L2 as an allophone among the languages?

```{r}
field %>% count(Name, trill_occ_L2) %>% count(trill_occ_L2)
```

What is the grand average congruent behavior?

```{r}
mean(field$Match)
```

97%!!!

What about only among those who have L1 without the distinction?

```{r}
field %>%
  filter(r_l_distinction_L1 == "0") %>%
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

100%! WOW.

What about only among those who have L1 without the distinction and no L2 that distinguishes?

```{r}
field %>%
  filter(r_l_distinction_L1 == "0") %>%
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  summarize(mean_match = mean(Match, na.rm = TRUE))
```

Also a 100%.

Compute average matching behavior per language and sort:

```{r}
field_avg <- field %>%
  group_by(Name) %>% 
  summarize(M = mean(Match)) %>% 
  arrange(desc(M)) %>% 
  mutate(percent = round(M, 2) * 100,
         percent = str_c(percent, '%'))

# Show:

field_avg %>% print(n = Inf)
```

Check some demographics, also to report in the paper. First, the number of participants per language:

```{r}
field %>% 
  count(Name, sort = TRUE) %>% print(n = Inf)
```

Then, the number of L1 speakers who have R/L distinction vs. who don't:

```{r}
field %>% count(r_l_distinction_L1) %>%
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many people do not have any L2?

```{r}
sum(is.na(field$L2)) / nrow(field)

# bilinguals:
1 - sum(is.na(field$L2)) / nrow(field)
```

Check how many people knew English as their L2:

```{r}
field %>% count(EnglishL2YesNo) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Of those that don't use a R/L distinction in their L1, how many use R/L distinction in their L2? (double-check if logic alright!)

```{r}
field %>%
  filter(r_l_distinction_L1 == '0') %>% 
  count(r_l_distinction_L2 == '1') %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

How many "pure" speakers were there?, i.e., those people that 1) don't know English, 2) don't use an L1 with a R/L distinction, and 3) don't know an L2 that distinguishes R/L.

```{r}
field %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  nrow()
```

7 people. All Palikúr speakers.

Let's check if this is correct. This gives the list of all participants for whom this applies.

```{r}
field %>% 
    filter(r_l_distinction_L1 == '0' & !EnglishL2YesNo & r_l_distinction_L1 == '0') %>% 
    print(n = 50)
```

Are these really "pure"? What languages do they speak?

```{r}
field %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  count(Language)
```

Yes, only Palikúr speakers.

Nevertheless, let's explore whether these also show matches?

```{r}
field %>% 
  filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
  filter(!EnglishL2YesNo) %>% 
  filter(r_l_distinction_L1 == '0') %>% 
  count(Match) %>% 
  mutate(prop = n / sum(n),
         percent = round(prop, 2) * 100,
         percent = str_c(percent, '%'))
```

Yes, a total 100%.



