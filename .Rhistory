# Remove rows with names "bouba-ort", "bouba-aud", "kiki-ort", and "kiki-aud"
field <- field %>%
filter(!file %in% c("bouba-ort", "bouba-aud", "kiki-ort", "kiki-aud"))
field[1, -1] <- gsub("rock", "r", field[1, -1])
field <- field %>%
select(-file) %>%
pivot_longer(everything(), names_to = "ID", values_to = "value") %>%
arrange(ID) %>%  # Arrange by ID
group_by(ID) %>%
mutate(audio = rep(c("r", "l"), each = n() / 2),  # Repeat "r" and "l" for each ID
response = ifelse(value %in% c("0", "NA", " "), NA, value)) %>%
ungroup() %>%
select(-value)  # Remove the original "value" column
View(field)
field <- mutate(field,
Language = str_extract(ID, '[A-Z]+'),
Participant = str_extract(ID, '\\d+'))
# Rename so that key columns match names:
demographics <- rename(demographics,
ID = subject,
Age = age,
Sex = gender,
L2 = "other-lang")
# Get only that what is needed:
demographics <- select(demographics,
ID, Age, Sex, L2)
# Join:
field <- left_join(field, demographics)
field <- filter(field, Age > 18)
field <- filter(field, Language != 'US')
field <- filter(field, Language != 'PL')
str(field)
field %>%
group_by(ID) %>%
summarise(AllResponsesEmptyOrNA = all(is.na(response) | response == "")) %>%
filter(AllResponsesEmptyOrNA)
field <- field %>%
filter(ID != "BE40")
field$Name <- NA
field[field$Language == 'BE', ]$Name <- 'english'
field[field$Language == 'DE', ]$Name <- 'german'
field[field$Language == 'SR', ]$Name <- 'portuguese'
field[field$Language == 'VA', ]$Name <- 'daakie'
field[field$Language == 'BR', ]$Name <- 'berber'
field[field$Language == 'PA', ]$Name <- 'palikur'
L2_info_field <- filter(field, !duplicated(ID)) %>% select(ID, Language, Name, L2)
L2_info_field <- L2_info_field %>%
mutate(L2 = ifelse(L2 %in% c('0', 'NA', ' '), NA, L2)) %>%
mutate(L2 = ifelse(is.na(L2), 'no_L2', L2))
L2_info_field <- mutate(L2_info_field,
EnglishL2YesNo = ifelse(grepl('english', L2, ignore.case = TRUE), TRUE, FALSE))
L2_info_field <- L2_info_field %>%
mutate(L2 = str_replace_all(L2, regex('British Sign Language', ignore_case = TRUE), 'BSL'),
L2 = str_replace_all(L2, regex('Mandarin', ignore_case = TRUE), 'chinese'),
L2 = str_replace_all(L2, regex('Moroccan Arabic', ignore_case = TRUE), 'arabic'),
L2 = str_replace_all(L2, regex('Standard Arabic', ignore_case = TRUE), 'arabic'))
L2_info_field <- L2_info_field %>%
mutate(L2 = ifelse(L2 %in% c("no_L2", "BSL"), L2, str_to_lower(L2))) %>%
rowwise() %>%
mutate(L2 = paste(unique(unlist(str_split(L2, ",\\s*"))), collapse = ", "))
L2_info_field$L2 <- sub("\\s*\\(restricted reading skills\\)", "", L2_info_field$L2)
L2_info_field <- L2_info_field %>%
mutate(r_l_distinction_L1 = NA,
trill_real_L1 = NA,
trill_occ_L1 = NA,
r_l_distinction_L2 = NA,
trill_real_L2 = NA,
trill_occ_L2 = NA)
L2_info_field <- L2_info_field %>%
left_join(languages_data, by = c("Name" = "Languages")) %>%
mutate(r_l_distinction_L1 = coalesce(r_l_distinction, r_l_distinction_L1),
trill_real_L1 = coalesce(trill_real, trill_real_L1),
trill_occ_L1 = coalesce(trill_occ, trill_occ_L1)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ))
# Save the original 'l2' column
original_L2 <- L2_info_field$L2
# Run the main code
L2_info_field <- L2_info_field %>%
separate_rows(L2, sep = ",\\s*") %>%
left_join(languages_data, by = c("L2" = "Languages")) %>%
group_by(ID) %>%
mutate(r_l_distinction_L2 = if(all(is.na(r_l_distinction))) NA else max(coalesce(r_l_distinction, r_l_distinction_L2), na.rm = TRUE),
trill_real_L2 = if(all(is.na(trill_real))) NA else max(coalesce(trill_real, trill_real_L2), na.rm = TRUE),
trill_occ_L2 = if(all(is.na(trill_occ))) NA else max(coalesce(trill_occ, trill_occ_L2), na.rm = TRUE)) %>%
select(-c(glottocode, r_l_distinction, trill_real, trill_occ)) %>%
distinct(ID, .keep_all = TRUE) %>%
ungroup()
# Replace the original 'L2' column
L2_info_field$L2 <- original_L2
rm(original_L2)
field <- left_join(field, select(L2_info_field, -Language), by = c('ID' = 'ID'))
field <- field %>%
rename(Name = Name.x,
L2_raw = L2.x,
L2_cleaned = L2.y) %>%
select(-Name.y)
ppt_N <- field %>% count(ID)
all(ppt_N$n == 2)
rm(ppt_N)
field %>% count(Name) %>%
mutate(n = n / 2) %>%
print()
langs <- read_csv(paste0(data, 'language_info_field.csv'))
field <- left_join(field, langs, by = "Language")
field <- field %>%
rename(Name = Name.y) %>%
select(-Name.x)
field$match = field$audio == field$response
field <- field %>%
mutate(match = ifelse(is.na(match), FALSE, match))
out <- field[, c('ID', 'Language', 'Name', 'Script', 'Family', 'Autotyp_Area', 'audio', 'match')]
# Rename column names for consistency with the main analysis:
out <- rename(out, Condition = audio)
write_csv(out, paste0(data,'field_raw_trials.csv'))
r_ppt <- field %>%
group_by(ID) %>%
summarise(Match = as.integer(all(match == TRUE)))
View(r_ppt)
r_ppt$Language <- field[match(r_ppt$ID, field$ID), ]$Language
r_ppt$Name <- field[match(r_ppt$ID, field$ID), ]$Name
r_ppt$Script <- field[match(r_ppt$ID, field$ID), ]$Script
r_ppt$Family <- field[match(r_ppt$ID, field$ID), ]$Family
r_ppt$Autotyp_Area <- field[match(r_ppt$ID, field$ID), ]$Autotyp_Area
r_ppt$L2 <- field[match(r_ppt$ID, field$ID), ]$L2_raw
r_ppt$EnglishL2YesNo <- field[match(r_ppt$ID, field$ID), ]$EnglishL2YesNo
r_ppt$r_l_distinction_L1 <- field[match(r_ppt$ID, field$ID), ]$r_l_distinction_L1
r_ppt$trill_real_L1 <- field[match(r_ppt$ID, field$ID), ]$trill_real_L1
r_ppt$trill_occ_L1 <- field[match(r_ppt$ID, field$ID), ]$trill_occ_L1
r_ppt$r_l_distinction_L2 <- field[match(r_ppt$ID, field$ID), ]$r_l_distinction_L2
r_ppt$trill_real_L2 <- field[match(r_ppt$ID, field$ID), ]$trill_real_L2
r_ppt$trill_occ_L2 <- field[match(r_ppt$ID, field$ID), ]$trill_occ_L2
write_csv(r_ppt, paste0(data, 'field_experiment_cleaned.csv'))
field <- read_csv(paste0(data, 'field_experiment_cleaned.csv'))
rm(L2_info, langs, out, ppt_N, r_ppt)
rm(L2_info_field, langs, out, ppt_N, r_ppt, demographics)
librarz(htmltools)
library(htmltools)
install.packages("htmltools")
install.packages("htmltools")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(tidyverse) # data processing
library(brms) # bayesian models
library(cmdstanr)
library(ggdist) # for plotting
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(parentfolder))
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(parentfolder))
parentfolder <- getwd()
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
data          <- paste0(parentfolder, '/data/')
packageVersion('tidyverse')
packageVersion('brms')
packageVersion('cmdstanr')
packageVersion('ggdist')
packageVersion('ggplot2')
source('theme_timo.R')
web <- read_csv(paste0(data, 'web_experiment_cleaned.csv'))
web_raw <- read_csv(paste0(data, '/web_raw_trials.csv'))
field <- read_csv(paste0(data, 'field_experiment_cleaned.csv'))
field_raw <- read_csv(paste0(data, '/field_raw_trials.csv'))
nrow(web)
web %>% count(Language) %>% nrow()
web %>% count(Family) %>% nrow()
web %>% count(Language, L1_distinction) %>% count(L1_distinction)
web %>% count(Language, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Language, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Language, r_l_distinction_L1)
web %>% count(Language, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Language, trill_real_L1) %>% count(trill_real_L1)
web %>% count(Language, trill_occ_L1) %>% count(trill_occ_L1)
web %>% count(Language, r_l_distinction_L2) %>% count(r_l_distinction_L2)
web %>% count(Language, trill_real_L2) %>% count(trill_real_L2)
web %>% count(Language, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Language, trill_occ_L2) %>% count(trill_occ_L2)
web %>% count(Language, trill_real_L2)
View(web)
web %>% count(Language, trill_occ_L1)
web %>% count(Language, trill_real_L1)
web %>% count(Language, trill_real_L1) %>% count(trill_real_L1)
web %>% count(Language) %>% nrow()
web %>% count(Language, trill_real_L1)
web %>% count(Language, trill_real_L1) %>% count(trill_real_L1)
str(web)
eb %>%
group_by(Language) %>%
summarise(MajorityTrillRealL1 = {
trill_counts = table(trill_real_L1)
most_common_trill = names(trill_counts)[which.max(trill_counts)]
return(as.numeric(most_common_trill))
})
web %>%
group_by(Language) %>%
summarise(MajorityTrillRealL1 = {
trill_counts = table(trill_real_L1)
most_common_trill = names(trill_counts)[which.max(trill_counts)]
return(as.numeric(most_common_trill))
})
web %>%
group_by(Language) %>%
summarise(MajorityTrillRealL1 = {
# Creating a frequency table for trill_real_L1 values
trill_counts = table(trill_real_L1)
# Finding the most common value of trill_real_L1
most_common_trill = as.numeric(names(trill_counts)[which.max(trill_counts)])
return(most_common_trill)
})
View(web)
web %>% count(Name, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Name) %>% nrow()
web %>% count(Name, r_l_distinction_L1) %>% count(r_l_distinction_L1)
web %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
unique(web$Name)
web %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
web %>% count(Name, trill_occ_L1) %>% count(trill_occ_L1)
web %>% count(Language, r_l_distinction_L2) %>% count(r_l_distinction_L2)
web %>% count(Name, r_l_distinction_L2) %>% count(r_l_distinction_L2)
web %>% count(Name, trill_real_L2) %>% count(trill_real_L2)
web %>% count(Language, trill_real_L2) %>% count(trill_real_L2)
web %>% count(Name, trill_occ_L2) %>% count(trill_occ_L2)
web %>% count(Name, trill_real_L1) %>% count(trill_real_L1)
mean(web$Match)
web %>%
filter(r_l_distinction_L2 == "0") %>%
summarize(mean_match = mean(Match, na.rm = TRUE))
web %>%
filter(r_l_distinction_L2 == "1") %>%
summarize(mean_match = mean(Match, na.rm = TRUE))
web %>%
filter(r_l_distinction_L2 == "0") %>%
summarize(mean_match = mean(Match, na.rm = TRUE))
web %>%
filter(r_l_distinction_L1 == "0") %>%
summarize(mean_match = mean(Match, na.rm = TRUE))
web %>%
filter(r_l_distinction_L1 == "0") %>%
filter(!EnglishL2YesNo) %>%
filter(r_l_distinction_L1 == '0') %>%
summarize(mean_match = mean(Match, na.rm = TRUE))
web_avg <- web %>%
group_by(Language) %>%
summarize(M = mean(Match)) %>%
arrange(desc(M)) %>%
mutate(percent = round(M, 2) * 100,
percent = str_c(percent, '%'))
# Show:
web_avg %>% print(n = Inf)
web %>%
count(Name, sort = TRUE) %>% print(n = Inf)
web_avg <- web %>%
group_by(Name) %>%
summarize(M = mean(Match)) %>%
arrange(desc(M)) %>%
mutate(percent = round(M, 2) * 100,
percent = str_c(percent, '%'))
web_avg %>% print(n = Inf)
web %>% count(r_l_distinction_L1) %>%
mutate(prop = n / sum(n),
percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
sum(is.na(web$L2)) / nrow(web)
1 - sum(is.na(web$L2)) / nrow(web)
web %>% count(EnglishL2YesNo) %>%
mutate(prop = n / sum(n),
percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
web %>%
filter(r_l_distinction_L1 == '0') %>%
count(r_l_distinction_L1 == '1') %>%
mutate(prop = n / sum(n),
percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
web %>%
filter(r_l_distinction_L1 == '0') %>%
count(r_l_distinction_L2 == '1') %>%
mutate(prop = n / sum(n),
percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
web %>%
filter(r_l_distinction_L1 == '1')
web %>%
filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
filter(!EnglishL2YesNo) %>%
filter(r_l_distinction_L1 == '0') %>%
nrow()
web %>%
filter(r_l_distinction_L1 == '0' & !EnglishL2YesNo & r_l_distinction_L1 == '0') %>%
print(n = 50)
web %>%
filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
filter(!EnglishL2YesNo) %>%
filter(r_l_distinction_L1 == '0') %>%
count(Language)
web %>%
filter(r_l_distinction_L1 == '0') %>%  # excludes English as well
filter(!EnglishL2YesNo) %>%
filter(r_l_distinction_L1 == '0') %>%
count(Match) %>%
mutate(prop = n / sum(n),
percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
mywarmup <- 4000
myiter <- 6000
table(web$Family, web$r_l_distinction_L1)
web <- mutate(web,
Order = factor(Order, levels = c('r_first', 'l_first')))
web %>% count(Order) %>%
mutate(prop = n / sum(n))
web %>% count(r_l_distinction_L1,trill_real_L1,trill_occ_L1) %>%
mutate(prop = n / sum(n))
web %>% count(trill_real_L1) %>%
mutate(prop = n / sum(n))
web %>% count(trill_occ_L1) %>%
mutate(prop = n / sum(n))
web %>% count(r_l_distinction_L1) %>%
mutate(prop = n / sum(n))
web %>% count(trill_real_L1) %>%
mutate(prop = n / sum(n))
web %>% count(r_l_distinction_L2) %>%
mutate(prop = n / sum(n))
web %>% count(trill_real_L2) %>%
mutate(prop = n / sum(n))
web %>% count(trill_occ_L2) %>%
mutate(prop = n / sum(n))
web <- mutate(web,
order_num = ifelse(Order == 'r_first', -0.5, +0.5))
web_mdl <- brm(Match ~ 1 + order_num + r_l_distinction_L1 + trill_real_L1 +
(1 + order_num|Language) +
(1 + order_num|Family),
data = web,
family = bernoulli(link = 'logit'),
backend = "cmdstanr",
seed = 42,
cores = 4,
iter = 2000,
warmup = 1000,
control = list(adapt_delta = 0.995,
max_treedepth = 13),
file = paste0(models, "web_mdl2.rds"))
web_mdl
plogis(fixef(web_mdl)[1, ][1])
plogis(fixef(web_mdl)[1, ][3]) # lwr bound
plogis(fixef(web_mdl)[1, ][4]) # upr bound
hypothesis(web_mdl, 'Intercept > 0')
hypothesis(web_mdl, 'r_l_distinction_L1 > 0')
hypothesis(web_mdl, 'trill_real_L1 > 0')
hypothesis(web_mdl, 'order_num > 0')
hypothesis(web_mdl, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 > 0', 'order_num > 0'))
hypothesis(web_mdl, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 < 0', 'order_num < 0'))
str(web)
# Calculating proportions
proportions <- web %>%
group_by(trill_real_L1) %>%
summarise(ProportionMatch1 = mean(Match == 1))
# Plotting
ggplot(proportions, aes(x = factor(trill_real_L1), y = ProportionMatch1, fill = factor(trill_real_L1))) +
geom_bar(stat = "identity") +
scale_x_discrete(name = "Trill Real L1") +
scale_y_continuous(name = "Proportion of Match = 1") +
ggtitle("Proportion of Match = 1 by Trill Real L1") +
theme_minimal()
rm(proportions)
# Calculating proportions
proportions <- web %>%
group_by(Order) %>%
summarise(ProportionMatch1 = mean(Match == 1))
# Plotting
ggplot(proportions, aes(x = factor(trill_real_L1), y = ProportionMatch1, fill = factor(trill_real_L1))) +
geom_bar(stat = "identity") +
scale_x_discrete(name = "Trill Real L1") +
scale_y_continuous(name = "Proportion of Match = 1") +
ggtitle("Proportion of Match = 1 by Trill Real L1") +
theme_minimal()
# Calculating proportions
proportions <- web %>%
group_by(Order) %>%
summarise(ProportionMatch1 = mean(Match == 1))
# Plotting
ggplot(proportions, aes(x = factor(Order), y = ProportionMatch1, fill = factor(Order))) +
geom_bar(stat = "identity") +
scale_x_discrete(name = "Trill Real L1") +
scale_y_continuous(name = "Proportion of Match = 1") +
ggtitle("Proportion of Match = 1 by Trill Real L1") +
theme_minimal()
rm(proportions)
web %>%
group_by(r_l_distinction_L1) %>%
summarize(prop = mean(Match)) %>%
mutate(percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
web %>%
group_by(trill_real_L1) %>%
summarize(prop = mean(Match)) %>%
mutate(percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
web %>%
group_by(Order) %>%
summarize(prop = mean(Match)) %>%
mutate(percent = round(prop, 2) * 100,
percent = str_c(percent, '%'))
posts <- posterior_samples(web_mdl)
View(posts)
posts <- select(posts,
b_Intercept:b_trill_real_L1)
posts <- pivot_longer(posts,
cols = b_Intercept:b_trill_real_L1,
names_to = 'coefficient',
values_to = 'posterior')
posts <- posts %>%
mutate(coefficient = ifelse(coefficient == 'b_Intercept', 'Intercept', coefficient),
coefficient = ifelse(coefficient == 'b_order_num', 'Order', coefficient),
coefficient = ifelse(coefficient == 'b_r_l_distinction_L1', 'R/L distinction', coefficient),
coefficient = ifelse(coefficient == 'b_trill_real_L1', 'Primary [r]', coefficient),
coefficient = factor(coefficient,
levels = rev(c('Intercept', 'Order', 'R/L distinction', 'Primary [r]'))))
# Aesthetics and geom:
p <- posts %>% ggplot(aes(y = coefficient, x = posterior)) +
geom_vline(aes(xintercept = 0), linetype = 2) +
stat_halfeye(alpha = 0.5, fill = 'steelblue')
# Axis labels and coordinates:
p <- p +
coord_cartesian(xlim = c(-4, +6)) +
scale_x_continuous(breaks = seq(-4, 6, 1)) +
xlab('Coefficient') +
ylab(NULL)
# Tweak cosmetics:
p <- p +
theme_timo +
theme(axis.title.x = element_text(margin = margin(t = 12, b = 0,
r = 0, l = 0),
face = 'bold', size = 14),
axis.text.x = element_text(face = 'bold', size = 12),
axis.text.y = element_text(face = 'bold', size = 12))
# Show and save:
p
ggsave(plot = p, filename = paste0(plots, 'main_model_coefficients.pdf'),
width = 8, height = 6)
# Setup data frame with predictors to get predictions for:
newdata <- data.frame(Language = unique(web$Language))
newdata$order_num <- 0
newdata$r_l_distinction_L1 <- web[match(newdata$Language, web$Language), ]$r_l_distinction_L1
newdata$Family <- web[match(newdata$Language, web$Language), ]$Family
# Get predictions and append to dataframe:
fit <- fitted(web_mdl, newdata = newdata,
re_formula = NULL, robust = TRUE)
# Setup data frame with predictors to get predictions for:
newdata <- data.frame(Language = unique(web$Language))
newdata$order_num <- 0
newdata$trill_real_L1 <- 0
newdata$r_l_distinction_L1 <- web[match(newdata$Language, web$Language), ]$r_l_distinction_L1
newdata$Family <- web[match(newdata$Language, web$Language), ]$Family
# Get predictions and append to dataframe:
fit <- fitted(web_mdl, newdata = newdata,
re_formula = NULL, robust = TRUE)
colnames(fit) = c('fit', 'se', 'lwr', 'upr')
newdata <- cbind(newdata, fit)
# Order predictions by descriptive average:
newdata <- arrange(newdata, fit)
newdata <- mutate(newdata,
Language = factor(Language, levels = newdata$Language))
sum(newdata$lwr > 0.5)
newdata$avg <- web_avg[match(newdata$Language, web_avg$Language), ]$M
newdata$Language <- web[match(newdata$Language, web$Language), ]$Name
newdata[newdata$Language == 'Chinese', ]$Language <- 'Mandarin Chinese'
newdata <- mutate(newdata,
Language = factor(Language, levels = newdata$Language))
# Aesthetics and geom:
p <- newdata %>%
ggplot(aes(x = Language, col = r_l_distinction_L1, y = fit,
ymin = lwr, ymax = upr)) +
geom_errorbar(aes(col = r_l_distinction_L1),
size = 1.6, width = 0.6) +
geom_point(size = 9, shape = 15) +
geom_hline(yintercept = 0.5, linetype = 2, size = 1.5, col = 'grey') +
geom_point(aes(y = avg), col = 'black', shape = 23, size = 8.5,
fill = 'white', stroke = 1.5)
# Axis labels:
p <- p +
labs(x = '', y = 'Proportion\nof congruent responses') +
ggtitle('Posterior medians and descriptive averages of\ncongruent responses by language and R/L contrast')
# Tweak cosmetics:
p <- p +
#scale_color_manual(values = c('#9C1437', '#355691')) + # ZAS-COLORS
theme_timo +
theme(axis.text.x = element_text(angle = 45, hjust = 1, face = 'bold',
size = 30),
axis.text.y = element_text(face = 'bold', size = 24),
axis.title = element_text(face = 'bold', size = 40),
axis.title.y = element_text(face = 'bold', size = 40,
margin = margin(t = 0, r = 35,
b = 0, l = 0)),
plot.title = element_text(face = 'bold', size = 40,
margin = margin(t = 0, r = 0,
b = 30, l = 0)),
legend.text = element_text(size = 30),
legend.title = element_blank(),
legend.position = c(0.95, 0.15),
legend.justification = c('right', 'bottom'))
# Show and save:
p
ggsave(plot = p, filename = paste0(plots, 'by_language_results.pdf'),
width = 28, height = 12)
hypothesis(web_mdl, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 < 0', 'order_num < 0'))
hypothesis(web_mdl, c('Intercept > 0', 'r_l_distinction_L1 > 0', 'trill_real_L1 < 0', 'order_num < 0'))
